---
title: "HEB_data_analysis"
author: "Schneider, Arnon, and Qi"
date: "8/28/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,include=FALSE,echo=FALSE,warning=FALSE}
#Loading library
library(psych)
library(readr)
library(optimx)
library(corrplot)
library(reshape)
library(reshape2)
library(lmerTest)
library(ggplot2)
library(scales)
library(ggbeeswarm)
library(Hmisc)
library(arm)
library(ez)
library(dplyr)
source("centerfactor.R")
```

```{r,include=FALSE,echo=FALSE,warning=FALSE}
#Load data
hebtrial <- read.csv('../data/heb_trial_clean_082819.csv')
hebindiv <- read.csv('../data/HEB_Data.csv')
hebtrial$task = as.factor(as.character(hebtrial$task)) # 0 means nonlinguistic and 1 means linguistic task
hebtrial$task_order = as.factor(as.character(hebtrial$task_order)) # 0 means nonlinguistic task comes first and 1 means linguistic task comes first
hebtrial$trial_order = as.factor(as.character(hebtrial$trial_order)) # 0 means foil comes first and 1 means target comes first
hebtrial$subject = as.factor(as.character(hebtrial$subject)) 
hebtrial$trial = as.factor(as.character(hebtrial$trial)) 
eng_trial<- hebtrial[which(hebtrial$language == "english"),]
eng_trial=droplevels(eng_trial)
contrasts(eng_trial$trial)=centerfactor(eng_trial$trial)
summary(eng_trial)
```
### Multi-level modeling in the English group based on the trial-by-trial data: fixed effects of task order (linguistic first or second), trial order (target or foil first), task (linguistic or non-linguistic), and trial (order of the test trials 1-25). Including task into random slope results in a non-converging model.
* no effect of task order
* significant effect of task
* significant effect of trial order (target first was more accurate)
* minimal effect of trial presentation order (later trials don't appear to be more accurate than earlier trials)

```{r}
eng.lmer <- glmer(trial_accuracy ~ 1 + task_order + task + trial_order + trial + gender + (1|subject), family = binomial, control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=2e5)), data = eng_trial)
summary(eng.lmer)
```
```{r}
eng.lmer <- glmer(trial_accuracy ~ 1 + task_order + task + (1|subject), family = binomial, control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=2e5)), data = eng_trial)
summary(eng.lmer)
```

#### trial order effect is significant within the linguistic task (target first is more accurate)
```{r lingtask}
eng_trial$task_code = 0
eng_trial[eng_trial$task=="0",]$task_code = 1
eng.ling.lmer <- glmer(trial_accuracy ~ 1 + task_order + task_code + trial_order + task_code:trial_order + (1+trial_order|subject), family = binomial, control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=2e5)), data = eng_trial)
summary(eng.ling.lmer)
```
#### trial order effect is not significant within the nonlinguistic task
```{r nonlingtask}
eng_trial$task_code = 0
eng_trial[eng_trial$task=="1",]$task_code = 1
eng.nonling.lmer <- glmer(trial_accuracy ~ 1 + task_order + task_code + trial_order + task_code:trial_order + (1+trial_order|subject), family = binomial, control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=2e5)), data = eng_trial)
summary(eng.nonling.lmer)
```
```{r}
eng.lmer <- glmer(trial_accuracy ~ 1 + task + (1|subject), family = binomial, control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=2e5)), data = eng_trial)
summary(eng.lmer)
```

### ANOVA testing the main effect of task (linguistic vs. non-linguistic) based on the overall accuracy data in the English group: *Marginal difference*
```{r}
# remove two participants who only had one task
hebindiv=hebindiv[is.na(hebindiv$accuracy)==0,]
hebindiv=subset(hebindiv,subject!="a_005")
hebindiv=subset(hebindiv,subject!="a_026")
eng_indiv=subset(hebindiv,group=="English")
summary(eng_indiv)
```

```{r,warning=FALSE}
taskanova <- ezANOVA(eng_indiv, accuracy, subject, within = .(task), type = 2, detailed = TRUE)
taskanova
```

### Testing the effect of familiarity on the overall accuracy (1) and the trial-by-trial accuracy (2) of the linguistic task in the English group
```{r}
eng_ling_indiv = subset(eng_indiv, Task = "Linguistic")
hist(eng_ling_indiv$familiarity)
```

```{r}
m1 = lm(accuracy~familiarity,data=eng_indiv[eng_indiv$task=="Linguistic",])
summary(m1)
```

#### plot the correlation between vocabulary and the SL accuracy in the English speakers.
```{r}
colnames(eng_indiv)[8]="Task"
ggplot() +
  theme_classic(base_size = 20.0) +
  xlab(label = 'Vocabuary (PVT)') +
  ylab(label = 'Overall Accuracy') +
  scale_x_continuous(breaks = pretty_breaks()) +
  scale_y_continuous(breaks = pretty_breaks()) +
  geom_point(aes(x = vocabulary,y = accuracy,colour = Task),data=eng_indiv, shape = 23, size = 3) +
  geom_smooth(aes(x = vocabulary,y = accuracy,colour = Task),data=eng_indiv,method = lm,formula = 'y ~ x',se = FALSE)
```

```{r}
eng_ling_trial=subset(eng_trial,task=="1")
eng_ling_trial$fam_ratings=as.factor(as.character(eng_ling_trial$fam_ratings))
contrasts(eng_ling_trial$fam_ratings)=centerfactor(eng_ling_trial$fam_ratings)
m1 = glmer(trial_accuracy~fam_ratings+(1|subject),family = binomial,data=eng_ling_trial)
summary(m1)
```

### Testing the correlation between vocabulary and each word's familiarity
```{r}
hebindiv_asl<-hebindiv[which(hebindiv$group=="English"),]
hebindiv_ling_eng<- hebindiv_asl[which(hebindiv_asl$task == "Linguistic"),]

cor.test(hebindiv_ling_eng$accuracy,hebindiv_ling_eng$Q1, method = "spearman")
cor.test(hebindiv_ling_eng$accuracy,hebindiv_ling_eng$Q2, method = "spearman")
cor.test(hebindiv_ling_eng$accuracy,hebindiv_ling_eng$Q3, method = "spearman")
cor.test(hebindiv_ling_eng$accuracy,hebindiv_ling_eng$Q4, method = "spearman")
cor.test(hebindiv_ling_eng$accuracy,hebindiv_ling_eng$Q5, method = "spearman")
```

### descriptive stats of the familiarity ranking
```{r}
library(likert)
library(psych)
library(ordinal)
# remove NA's
hebrank=subset(hebindiv_ling_eng,subject!="a_050")
hebrank=subset(hebrank,subject!="a_002")
hebrank=subset(hebrank,subject!="a_035")
hebrank=hebrank[c(11:15)]
hebrank$Q1 = factor(hebrank$Q1,
                       levels = c("0", "1", "2", "3", "4", "5"),
                       ordered = TRUE)
hebrank$Q2 = factor(hebrank$Q2,
                       levels = c("0", "1", "2", "3", "4", "5"),
                       ordered = TRUE)
hebrank$Q3 = factor(hebrank$Q3,
                       levels = c("0", "1", "2", "3", "4", "5"),
                       ordered = TRUE)
hebrank$Q4 = factor(hebrank$Q4,
                       levels = c("0", "1", "2", "3", "4", "5"),
                       ordered = TRUE)
hebrank$Q5 = factor(hebrank$Q5,
                       levels = c("0", "1", "2", "3", "4", "5"),
                       ordered = TRUE)
headTail(hebrank)
summary(hebrank)
results=likert(hebrank)
summary(results)
plot(results,
     type="heat",
           low.color = "white",
           high.color = "red",
           text.color = "black",
           text.size = 4,
           wrap = 50)
```
### test whether different items have different familiarity rankings: Q4 is significantly different from Q3, and marginally from Q2 and Q5.
```{r}
library(dunn.test)
hebrank=subset(hebindiv_ling_eng,subject!="a_050")
hebrank=subset(hebrank,subject!="a_002")
hebrank=subset(hebrank,subject!="a_035")
hebrank=hebrank[c(1,11:15)]
hebrank=melt(hebrank,id=1)
colnames(hebrank)[2]="item"
colnames(hebrank)[3]="ranking"
kruskal.test(ranking ~ item,
             data = hebrank)
DT = dunn.test(hebrank$ranking,hebrank$item, method="bh")      # Adjusts p-values for multiple comparisons;
```
### Testing the relationship between vocabulary and performance across tasks in the English group.
```{r}
glmvoc = glm(accuracy~vocabulary*Task,data=eng_indiv)
summary(glmvoc)
```

### Testing the group by task interaction in a multi-level model based on the trial-by-trial data
```{r}
hebgroup.lmer <- glmer(trial_accuracy ~ 1 + language * task + (1|subject), family = binomial,control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=2e5)), data = hebtrial)
summary(hebgroup.lmer)
```

### Testing the correlation between linguistic and non-linguistic tasks for English Speakers
```{r}
hebindiv_eng<-hebindiv[which(hebindiv$group=="English"),]
hebindiv_ling_eng<- hebindiv_eng[which(hebindiv_eng$task == "Linguistic"),]
hebindiv_nonling_eng<- hebindiv_eng[which(hebindiv_eng$task == "Non-Linguistic"),]
cor.test(hebindiv_ling_eng$accuracy,hebindiv_nonling_eng$accuracy, method = "pearson")
```

### Testing the correlation between linguistic and non-linguistic tasks for Hebrew Speakers
```{r}
hebindiv_heb<-hebindiv[which(hebindiv$group=="Hebrew"),]
hebindiv_ling_heb<- hebindiv_heb[which(hebindiv_heb$task == "Linguistic"),]
hebindiv_nonling_heb<- hebindiv_heb[which(hebindiv_heb$task == "Non-Linguistic"),]
cor.test(hebindiv_ling_heb$accuracy,hebindiv_nonling_heb$accuracy, method = "pearson")
```

### plot the bar graphs to illustrate interaction between two groups and two tasks
```{r}
ggplot() +
  theme_classic(base_size = 20.0) +
  ylab(label = 'Overall Accuracy (%)') +
  scale_y_continuous(breaks = pretty_breaks()) +
  geom_bar(aes(y = accuracy, x = group,fill = as.factor(group)),data=hebindiv,colour="black",fun.data = mean_sdl,stat = 'summary') +
  geom_beeswarm(aes(x = group,y = accuracy),data=hebindiv,dodge.width=0.9,cex=2.5) +
  facet_wrap(facets = ~task) +
  scale_x_discrete(name = 'task')+   
  scale_fill_brewer(palette = 'Set2') +
  theme(legend.position = "none")
```

### plot the line graphs to illustrate interaction between two groups and two tasks
```{r}
d <- hebindiv %>%
       select(task, group, accuracy) %>%  # select relevant variables
       mutate(task = factor(task, labels = c("Linguistic", "Non-linguistic")),
              group = factor(group))

head(d)
d %>% 
  group_by(task, group) %>%
  summarise(accuracy_mean = mean(accuracy))
sum_d <- d %>% 
          group_by(task, group) %>%
          summarise(accuracy_mean = mean(accuracy),
                    se   = sd(accuracy)/sqrt(n()))
sum_d
```

```{r}
pd <- position_dodge(width = 0)
sum_d %>%
  ggplot(aes(x = task, y = accuracy_mean, group = group)) +
    geom_line(aes(linetype = group), position = pd) +
    geom_errorbar(aes(ymin = accuracy_mean - se, ymax = accuracy_mean + se),
                  width = .1, position = pd) +
    geom_point(size = 4, position = pd) +
    geom_point(size = 3, color = "white", position = pd) + 
    guides(linetype = guide_legend("Group")) +
    labs(x = "Tasks",
         y = "Overall Accuracy (%)") +
  theme(
    text=element_text(size=20),
    panel.background = element_rect(fill = "white"),         # Set plot background to white
    legend.key  = element_rect(fill = "white"),              # Set legend item backgrounds to white
    axis.line.x = element_line(colour = "black", size = 1),  # Add line to x axis
    axis.line.y = element_line(colour = "black", size = 1)   # Add line to y axis
  )
```